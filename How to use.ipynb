{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6d822c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_tokenizer import BytePairEncodingTokenizer,WordPieceTokenizer\n",
    "import time\n",
    "\n",
    "with open('preprocessed_text.txt','r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "\n",
    "wp_tok = WordPieceTokenizer(num_tokens=20000,max_word_count=100000)\n",
    "bpe_tok = BytePairEncodingTokenizer(num_tokens=20000,max_word_count=100000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59715df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"one of the other reviewers has mentioned that after watching just 1 oz episode you ' ll be hooked . they are right , as this is exactly what happened with me . the first thing that struck me about oz was its brutality and unflinching scenes of violence , which set in right from the word go . trust me , this is not a show for the faint hearted or timid . this show pulls no punches with regards to drugs , sex or violence . its is hardcore , in the classic use of the word . it is called oz as that is the nickname given to the oswald maximum security state penitentary . it focuses mainly on emerald city , an experimental section of the prison where all the cells have glass fronts and face inwards , so privacy is not high on the agenda . em city is home to many . aryans , muslims , gangstas , latinos , christians , italians , irish and more . so scuffles , death stares , dodgy dealings and shady agreements are never far away . i would say the main appeal of the show is due to the fact that \""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5f7b5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time : 1.36 minutes\n"
     ]
    }
   ],
   "source": [
    "# training wordpiece tokenizer\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "wp_tok([text])\n",
    "wp_tok.train(iterations=3,min_pair_freq=100)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'total training time : {round((end - start) / 60 , 2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eae62beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total training time : 1.52 minutes\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "bpe_tok([text])\n",
    "bpe_tok.train(iterations=3,min_pair_freq=100)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "print(f'total training time : {round((end - start) / 60 , 2)} minutes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28c08f45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20013, 20013)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(wp_tok.vocab),len(bpe_tok.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4cb8b452",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20013 = 20000 words + 5 special tokens + 8 punctuations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28f904ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizing sequences\n",
    "\n",
    "# set maxlen\n",
    "wp_tok.maxlen = 20\n",
    "bpe_tok.maxlen = 20\n",
    "\n",
    "seq = \"the french lost in normandy ?\"\n",
    "\n",
    "wp_seq = wp_tok.tokenize(seq)\n",
    "bpe_seq = bpe_tok.tokenize(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7343b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cls> the french lost in norman ##d <unk> ? <sep>'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wordpiece tokenization\n",
    "\n",
    "' '.join(wp_tok.i2w[t] for t in wp_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85d3a40e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<cls> the french lost in nor mandy ? <sep>'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# byte-pair tokenization\n",
    "\n",
    "' '.join(bpe_tok.i2w[t] for t in bpe_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d1d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "wp_padded_seq = wp_tok.add_padding(wp_seq)\n",
    "bpe_padded_seq = bpe_tok.add_padding(bpe_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ec2ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 721, 441, 15, 3259, 8304, 3, 59, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wp_padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba2bbfbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 5, 721, 441, 15, 939, 8086, 59, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_padded_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "66f72a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moisturiser  --  <unk>\n",
      "trains  --  trains\n",
      "translvanian  --  trans ##l ##v ##a ##n ##i ##a ##n\n",
      "bachar  --  bach ##a ##r\n",
      "lucina  --  luc ##in ##a\n",
      "crucification  --  <unk>\n",
      "amovie  --  am ##o ##v ##i ##e\n",
      "socomm  --  so ##co ##mm\n",
      "wesa  --  wes ##a\n",
      "tasogare  --  tas ##o ##g ##a ##r ##e\n",
      "outfox  --  out ##f ##o ##x\n",
      "eire  --  e ##i ##r ##e\n",
      "disfigurement  --  <unk>\n",
      "uresevsky  --  u ##r ##e ##s ##e ##v ##s ##k <unk>\n",
      "oneshoe  --  ones ##h ##o ##e\n",
      "thugaboo  --  thug ##a ##b ##oo\n",
      "razed  --  ra ##z ##e ##d\n",
      "proprieties  --  prop ##r ##i ##e ##t ##ies\n",
      "kids  --  kids\n",
      "sanitizes  --  san ##i ##t ##i ##z ##e ##s\n"
     ]
    }
   ],
   "source": [
    "# testing subword splits\n",
    "\n",
    "words = list(set(text.split()))[3000:3020]\n",
    "\n",
    "for w in words:\n",
    "    \n",
    "    print(w,' -- ',wp_tok._split_oov(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4d3a8bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "moisturiser  --  moi stu rise r\n",
      "trains  --  trains\n",
      "translvanian  --  trans l van ian\n",
      "bachar  --  b ac har\n",
      "lucina  --  luc in a\n",
      "crucification  --  cr u c if i cat i on\n",
      "amovie  --  a movie\n",
      "socomm  --  so com m\n",
      "wesa  --  we sa\n",
      "tasogare  --  ta so ga re\n",
      "outfox  --  out fox\n",
      "eire  --  e i re\n",
      "disfigurement  --  dis figure men t\n",
      "uresevsky  --  u re se vs ky\n",
      "oneshoe  --  one shoe\n",
      "thugaboo  --  thug abo o\n",
      "razed  --  r az ed\n",
      "proprieties  --  pro pr ie ties\n",
      "kids  --  kids\n",
      "sanitizes  --  san it i z es\n"
     ]
    }
   ],
   "source": [
    "for w in words:\n",
    "    \n",
    "    print(w,' -- ',bpe_tok._split_oov(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f10b9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
